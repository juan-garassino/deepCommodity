{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå§ Weather Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's import the usual libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_columns\", None)\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manipulating temporal data is tricky, let's also import üìö [`typing`](https://docs.python.org/3/library/typing.html) to check the types of variables we will be dealing with in our Python functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) The weather temperature challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0.0) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ **Goals:**\n",
    "- Prepare a dataset to be fed into a Recurrent Neural Network\n",
    "- Develop a better understanding of Time Series\n",
    "\n",
    "‚ùóÔ∏è **Warning/Disclaimer**:\n",
    "- This challenge is truly designed to help you understand **how to deal with temporal data**, using an LSTM architecture as a _tool_, not to focus on the different gates of the LSTM or designing the \"best\" recurrent network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **ML target**:\n",
    "* In this challenge, we want to **predict the temperature in the next 3, 6, 9, 12... hours**... \n",
    "* ...based on a sequence of weather features such as the _past temperature_, the _atmospheric pressure_, the _humidity_, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0.1) The weather dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0.1.1) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üå§ This challenge uses a [**weather time series dataset**](https://www.bgc-jena.mpg.de/wetter/) recorded by the [**Max-Planck-Institute for Biogeochemistry**](https://www.bgc-jena.mpg.de/index.php/Main/HomePage). This dataset contains $14$ different features such as _air temperature_, _atmospheric pressure_ and _humidity_ that were collected starting in 2003 every 10 minutes (~ 420k rows). But for efficiency, you will use \"only\" the data collected between 2009 and 2016 every three hours. Indeed, this time interval seems reasonable to observe the evolution of the temperature throughout a given day.\n",
    "\n",
    "üõ† We've already performed the following feature engineering steps for you:\n",
    "- taking every $18$th record to focus on predictions every three hours $ ( 18 =  \\frac{6 records}{hour} \\times 3 hours)$\n",
    "- replacing absurd values\n",
    "- _wind_: computing the wind directions as wind vectors with coordinates (`Wx`, `Wy`)\n",
    "- computing _the daily and yearly periodicities_, stored through (`Day sin`, `Day cos`) and (`Year sin`, `Year cos`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Keep this section for later) Downloading the original dataset and engineer the features manually\n",
    "\n",
    "_(Toggle the section to hide it for the moment)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü•ã If you want to practice your feature engineering skills, feel free to download the original dataset and work on it (but not today, there are many questions and reading sections to cover üòâ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Uncomment later -not today- to download the original  #\n",
    "# dataset and try to perform the features engineering   #\n",
    "# by yourself                                           #\n",
    "#########################################################\n",
    "\n",
    "\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "\n",
    "raw = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"raw.shape = {raw.shape}\")\n",
    "display(raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting each feature to detect their type and null values\n",
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice [start:stop:step], \n",
    "# starting from index 5, take every 6th record\n",
    "# to get only hourly records\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"Date Time\" column to a datetime format\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataset\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fixing the wv\n",
    "\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "## Fixing the max wv\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind : Wd degrees from 0 to 360 egrees\n",
    "# Angles do not make good models inputs because 0 and 360 should be \"close\"\n",
    "\n",
    "print('-'*50)\n",
    "print(\"Working with angles...\")\n",
    "\n",
    "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], \n",
    "           bins=(50, 50), \n",
    "           vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind Direction [deg]')\n",
    "plt.ylabel('Wind Velocity [m/s]')\n",
    "plt.show()\n",
    "\n",
    "# It is much easier for the model to interpret\n",
    "# the wind direction and the wind velocity through a vector\n",
    "\n",
    "\n",
    "# Convert degrees to radians and store the values into wd_rad\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "# Calculate the wind x and y components and store then in two new columns\n",
    "# `Wx` and `Wy`\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "# Calculate the max wind x and y components and store then in two new columns\n",
    "# `max Wx` and `max Wy`\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "print('-'*50)\n",
    "print(\"Working with wind vectors\")\n",
    "\n",
    "plt.hist2d(df['Wx'], df['Wy'], \n",
    "           bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]')\n",
    "ax = plt.gca()\n",
    "ax.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly to the wind direction, the time in seconds is not a useful model input\n",
    "# The weather dataset has clear daily and yearly periodicities\n",
    "# Using sine and cosine functions, we can compute:\n",
    "# - the time of the day\n",
    "# - the time of the year\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select every 3 hours \n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trust us and start from this already preprocessed dataset for this challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/weather_every_three_hours_engineered.csv\"\n",
    "df = pd.read_csv(url).drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ In the preprocessed dataset, we have :\n",
    "- $23$k rows  (~ 8 years of weather data)\n",
    "- $19$ features composed of:\n",
    "    - $1$ <font color=green>**target**</font> (we will use the past values of the temperature as a feature)\n",
    "    - $18$ <font color=orange>**past covariates**</font> (= features which past values are known)\n",
    "    - $0$ <font color=blue>**future covariates**</font> (= features which future values are known, e.g. public holidays)\n",
    "\n",
    "    \n",
    "<img src='https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/time-series-covariates.png'>\n",
    "\n",
    "üë®üèª‚Äçüè´ This weather dataset is a DataFrame (dimension = 2) which is a single Time Series from the beginning of 2009 to the end 2016 with records every 3 hours. \n",
    "\n",
    "* `df.shape = (n_timesteps, n_features) = (23363, 19)`\n",
    "\n",
    "üéØ The goal is to predict the temperature in 3, 6, 9, 12, ... hours using the past values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the global variables of our dataset\n",
    "TARGET = 'T (degC)'\n",
    "N_TARGETS = 1\n",
    "N_FEATURES = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0.0.2) Visualising your Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìà  Here is the ***evolution of some features over time***:\n",
    "* `T (degC)` (temperature)\n",
    "* `p (mbar)` (atmospheric pressure)\n",
    "* `rho (g/m**3)` (atmospheric density)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = [TARGET, 'p (mbar)', 'rho (g/m**3)']\n",
    "plot_features = df[plot_cols]\n",
    "plot_features.index = df.index\n",
    "plot_features.plot(subplots = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomed_slice = slice(1000,1100)\n",
    "\n",
    "plot_features = df.loc[zoomed_slice, plot_cols]\n",
    "plot_features.plot(subplots = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (1.0) The big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Step 1: Cross-Validation in Time Series [FOLDS] </u></b>\n",
    "\n",
    "* Starting from this single Time Series, we will create <font color=\"#c91ac9\">**FOLDS**</font>...\n",
    "* ... and train/evaluate our LSTM on these different <font color=\"#c91ac9\">**FOLDS**</font> to conclude about the robustness of the neural network\n",
    "* It is very common to create ***hundreds*** of <font color=\"#c91ac9\">**FOLDS**</font> in Time Series forecasting, in order to to cover all types of external conditions: e.g.\n",
    "    - crash market periods üìâ\n",
    "    - bull markets üìà\n",
    "    - atone markets üò¥, etc...\n",
    "\n",
    "<b><u>Step 2: Holdout method within each fold [TRAIN-TEST SPLIT]</u></b>\n",
    "\n",
    "* For each <font color=\"#c91ac9\">**FOLD**</font>, we will do a TRAIN-TEST SPLIT to:\n",
    "    * <font color=blue>**fit**</font> the model on the <font color=blue>**train**</font> set \n",
    "    * and <font color=\"#ff8005\">**evaluate**</font> it on the <font color=\"#ff8005\">**test**</font> set\n",
    "    * Always split the train set **chronologically** before the test set!\n",
    "\n",
    "üëá The first two steps can be summarized in the following image that contains 4 FOLDS:\n",
    "\n",
    "<img src=\"https://bit.ly/3yLoa92\" alt=\"Time Series Cross Validation\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "<b><u>Step 3: Sampling SEQUENCES in both the train set and the test set</u></b>\n",
    "\n",
    "In each <font color=blue>**train**</font> set and each <font color=\"#ff8005\">**test**</font> set, we will create <font color=magenta>**random sequences**</font> as illustrated down below üëá:\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.1) Creating  <font color=\"#c91ac9\">**FOLDS**</font> for cross-validation\n",
    "\n",
    "Each of them with shape `(FOLD_LENGTH, n_features)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåê Let's define some global variables that we will use for our tests everywhere in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------- #\n",
    "# Let's consider FOLDS with a length of 3 years       #\n",
    "# (2 years will be used for train, 1 for test!)       #\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "FOLD_LENGTH = 8*365 * 3 # every 3 hrs x 8 = 24h\n",
    "                        # three years\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# Let's consider FOLDS starting every trimester       #\n",
    "# --------------------------------------------------- #\n",
    "    \n",
    "FOLD_STRIDE = 8*91 # every 3 hrs x 8 = 24h\n",
    "                   # 1 quarter = 91 days\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# Let's consider a train-test-split ratio of 2/3      #\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (<font color=\"#c91ac9\">FOLDS</font>)** ‚ùì\n",
    "\n",
    "Code the function `get_folds` below that we will use to create folds  `folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(\n",
    "    df: pd.DataFrame, \n",
    "    fold_length: int,\n",
    "    fold_stride: int) -> List[pd.DataFrame]:\n",
    "    '''\n",
    "    This function slides through the Time Series dataframe of shape (n_timesteps, n_features) to create folds\n",
    "    - of equal `fold_length`\n",
    "    - using `fold_stride` between each fold\n",
    "    \n",
    "    Returns a list of folds, each as a DataFrame\n",
    "    '''\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "\n",
    "print(f'The function generated {len(folds)} folds.')\n",
    "print(f'Each fold has a shape equal to {folds[0].shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('folds',\n",
    "                         number_of_folds = len(folds),\n",
    "                         fold_shape = folds[0].shape)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This amount of <font color=\"#c91ac9\">**FOLDS**</font> should be enough to cross-validate our model correctly !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.2) Temporal <font color=blue>**Train**</font>/<font color=\"#ff8005\">**Test**</font> Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ Let's focus on one fold for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = folds[0]\n",
    "fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è We want to split this fold **chronologically** into:\n",
    "\n",
    "- a <font color=blue>train</font> dataframe\n",
    "- a <font color=\"#ff8005\">test</font> dataframe\n",
    "\n",
    "that will contain all the data we need to be able to sample many `(X_i, y_i)` pairs in each dataframe in a next step! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `INPUT_LENGTH` of each `X_i` is going to be equal to 2 weeks (it is quite a common period for weather forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH = 8 * 14 # records every 3 hours x 8 = 24 hours\n",
    "                      # two weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (temporal <font color=blue>train</font>-<font color=orange>test</font> split)** ‚ùì\n",
    "\n",
    "Code the function `train_test_split` down below which:\n",
    "- <i>(input)</i> given a `fold` (like above), a `train_test_ratio` (e.g 0.8) and an `input_length` (fixed)\n",
    "- <i>(output)</i> a tuple of (`fold_train`, `fold_test`) dataframes\n",
    "\n",
    "\n",
    "‚ùóÔ∏èHints to avoid data leakage‚ùóÔ∏è \n",
    "\n",
    "- `fold_train` last index will become the last `y_train` later on\n",
    "- `fold_test` first index will be used to create the first `X_test`\n",
    "- To avoid data leakage, `y_train_last` should be JUST before `y_test_first`\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/explanations_for_train_test_split_temporal.png\" alt=\"train_test_split_temporal\" width=\"500\" height=\"500\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fold:pd.DataFrame,\n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int) -> Tuple[pd.DataFrame]:\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe (fold_train, fold_test)\n",
    "    from which one can sample (X,y) sequences.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))   \n",
    "    '''\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_train, fold_test) = train_test_split(fold, TRAIN_TEST_RATIO, INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('holdout',\n",
    "                         train_index_start = fold_train.index.start,\n",
    "                         train_index_stop = fold_train.index.stop,\n",
    "                         test_index_start = fold_test.index.start,\n",
    "                         test_index_stop = fold_test.index.stop)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.3) Create (X, y) sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have splitted our fold into a <font color=\"blue\">train</font> set and a <font color=\"#ff8005\">test</font> set, it is time to:\n",
    "- üèã sample lots of sequences $(X_i, y_i)$ on which the model will be <font color=\"blue\">trained</font>\n",
    "- üë©üèª‚Äçüè´ sample lots of sequences $(X_i, y_i)$ on which the model will be <font color=\"#ff8005\">evaluated</font>\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"300\" height=\"300\"> \n",
    "\n",
    "üéØ Our goal is to create 3D-arrays `(X_train, y_train)` and `(X_test, y_test)` containing all the SEQUENCES we need from this fold:\n",
    "\n",
    "* `X_train.shape = (n_samples_train, input_length, n_features)`\n",
    "* `y_train.shape = (n_samples_train, output_length, n_targets)`\n",
    "\n",
    "üëâ Notice that we are now dealing with **3D arrays** instead of **2D DataFrames** time-series\n",
    "\n",
    "<img src=\"https://bit.ly/3bOhKNj\" alt=\"3d arrays time series\" width=\"1200\" height=\"800\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT X\n",
    "print(f'N_FEATURES = {N_FEATURES}')\n",
    "print(f'INPUT_LENGTH = {INPUT_LENGTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è `X` is the **input** of our model. \n",
    "- It contains $19$ features: the past values of the <font color=green>**target**</font> + $18$ <font color=orange>**past-covariates**</font>\n",
    "- Each sequence has a length equal to $112$ timesteps (=$2$ weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET Y\n",
    "print(f'N_TARGETS = {N_TARGETS}')\n",
    "\n",
    "# Let's only predict 1 value ahead of us\n",
    "OUTPUT_LENGTH = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è `y` is the <font color=green>**target**</font> that we want to predic:t\n",
    "- It is the value at the single next timestep (=3 hours later)\n",
    "- We could also predict `OUTPUT_LENGTH > 1`, i.e several values in the future (3 hours later, 6 hours later, 9 hours later, ...) but let's keep it simple here and just try to predict the next point (in 3 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° To create these SEQUENCES within the <font color=\"blue\">train</font> set and the <font color=\"#ff8005\">test</font> set, you have several options, among them:\n",
    "- üé≤ <u><i>Option 1</i></u>: creating these sequences by randomly sampling $(X_i, y_i)$ from <font color=\"blue\">fold_train</font> and <font color=\"#ff8005\">fold_test</font>.\n",
    "- ‚åöÔ∏è <u><i>Option 2</i></u>: scanning a fold chronologically and create all the possible pairs $(X_i, y_i)$. \n",
    " \n",
    "\n",
    "üëâ Let's focus on the first option: random sampling\n",
    "\n",
    "üéÅ If you want to scan the folds chronologically, we provided the solution in the section and you can come back to it later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2.1) Option 1: Create (X, y) by random sampling in each split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá We will code:\n",
    "\n",
    "* 1Ô∏è‚É£ a function `get_Xi_yi` to generate a single sequence randomly from within a fold\n",
    "\n",
    "* 2Ô∏è‚É£ a function `get_X_y` to generate 3D-arrays containing multiple sequences from a fold, calling the first function `get_Xi_yi` many times over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.2.2.1) Generating one random sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/get_xi_yi.png\" alt=\"one sequence\" width=\"400\" height=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (extracting a random sequence from a fold)** ‚ùì\n",
    "\n",
    "Code the function `get_Xi_yi` down below which:\n",
    "- <i>(input)</i> given a fold, an `input_length` and an `output_length`\n",
    "- <i>(output)</i> returns a sequence $(X_i,y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xi_yi(\n",
    "    fold:pd.DataFrame, \n",
    "    input_length:int, \n",
    "    output_length:int):\n",
    "    '''\n",
    "    - given a fold, it returns one sequence (X_i, y_i)\n",
    "    - with the starting point of the sequence being chosen at random\n",
    "    '''\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ ***Test your code below***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i, y_train_i = get_Xi_yi(fold_train, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "X_test_i, y_test_i = get_Xi_yi(fold_test, INPUT_LENGTH, OUTPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('sequence',\n",
    "                         x_train_i_shape = X_train_i.shape,\n",
    "                         y_train_i_shape = y_train_i.shape,\n",
    "                         x_test_i_shape = X_test_i.shape,\n",
    "                         y_test_i_shape = y_test_i.shape)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced check üòà \n",
    "# You should not allow some truncated (X_i,y_i) pairs to be generating,\n",
    "# should you start sampling too close from the end of the fold... !\n",
    "\n",
    "X_last, y_last = get_Xi_yi(fold_test, input_length=len(fold_test)-1, output_length=OUTPUT_LENGTH)\n",
    "assert y_last.values == fold_test.iloc[-1,:][TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.2.2.2) Generating multiple random sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (extracting multiple random sequence from a fold)** ‚ùì\n",
    "\n",
    "Code the function `get_X_y` down below which:\n",
    "- <i>(input)</i> given a fold, a `number_of_sequences` an `input_length` and an `output_length`\n",
    "- <i>(output)</i> returns $(X,y)$ \n",
    "\n",
    "_Don't forget to use the `get_Xi_yi` function that you have just coded!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(\n",
    "    fold:pd.DataFrame,\n",
    "    number_of_sequences:int,\n",
    "    input_length:int,\n",
    "    output_length:int\n",
    "):\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 6666 # number_of_sequences_train\n",
    "N_TEST =  3333 # number_of_sequences_test\n",
    "\n",
    "X_train, y_train = get_X_y(fold_train, N_TRAIN, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "X_test, y_test = get_X_y(fold_test, N_TEST, INPUT_LENGTH, OUTPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('multiple_sequences',\n",
    "                         x_train_shape = X_train.shape,\n",
    "                         y_train_shape = y_train.shape,\n",
    "                         x_test_shape = X_test.shape,\n",
    "                         y_test_shape = y_test.shape)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2.2) (Don't read this now, keep for later) üéÅ Option 2: Scanning  chronologically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated earlier, there are multiple ways to extract sequences from a fold. \n",
    "\n",
    "- üé≤ In the previous section, you coded:\n",
    "    - `get_Xi_yi` which randomly samples _one_ sequence \n",
    "    - and `get_X_y` which randomly generates _multiple_ sequences\n",
    "\n",
    "- ‚åöÔ∏è In this section, we provide you a unique function `get_X_y_strides`.\n",
    "    - It scans a fold chronologically based on:\n",
    "         - an `input_length` (let's still use `INPUT_LENGTH = 8 * 14`, i.e. two weeks) \n",
    "         - and a `sequence_stride` (think about a one-dimensional convolutional operation!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's scan the fold with a temporal stride of 3 hours (the minimum one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_STRIDE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_strides(fold: pd.DataFrame, input_length: int, output_length: int, sequence_stride: int):\n",
    "    '''\n",
    "    - slides through a `fold` Time Series (2D array) to create sequences of equal\n",
    "        * `input_length` for X,\n",
    "        * `output_length` for y,\n",
    "    using a temporal gap `sequence_stride` between each sequence\n",
    "    - returns a list of sequences, each as a 2D-array time series\n",
    "    '''\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(0, len(fold), sequence_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (i + input_length + output_length) > len(fold):\n",
    "            break\n",
    "        X_i = fold.iloc[i:i + input_length, :]\n",
    "        y_i = fold.iloc[i + input_length:i + input_length + output_length, :][[TARGET]]\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüéì Some clarifications about scanning a fold sequentially :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FOLD_LENGTH\") \n",
    "print(f\"= {FOLD_LENGTH} timesteps\")\n",
    "print(f\"= {int(FOLD_LENGTH/8)} days\") # 8 records per day, every 3 hours\n",
    "print(f\"= {int(FOLD_LENGTH/8/7)} weeks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y_strides(fold_train, INPUT_LENGTH, OUTPUT_LENGTH, SEQUENCE_STRIDE)\n",
    "X_test, y_test = get_X_y_strides(fold_test, INPUT_LENGTH, OUTPUT_LENGTH, SEQUENCE_STRIDE)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Illustration down below if *SEQUENCE_STRIDE = 1 week*\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/scanning_a_time_series_chronologically_v3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The MAE as a metrics to monitor the temperature prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Absolute Error seems to be a reasonable metrics to evaluate a model's capability to predict the temperature:\n",
    "\n",
    "$$ MAE = \\frac{1}{n_{samples}} \\times \\sum_{i = 1}^{n_{samples}} |y_{true}^{(i)} - y_{pred}^{(i)}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1) A Recurrent Neural Network: the `LSTM`\n",
    "\n",
    "üöÄ It is time to design a Recurrent Neural Network and hopefully beat the baseline üí™ !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (RNN)** ‚ùì \n",
    "\n",
    "- Create a function `init_model` which builds and compiles a simple Recurrent Neural Network with an LSTM layer\n",
    "- Don't forget to normalize your data with a [üìö Normalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "def init_model(X_train, y_train):\n",
    "    \n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model(X_train, y_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ† üéÅ üìâ We coded a function `plot_history` for you to visualize the training of your RNN over epochs. This function shows both the evolution of the loss function (MSE) and metrics (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # --- LOSS: MSE --- \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('MSE')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- METRICS:MAE ---\n",
    "    \n",
    "    ax[1].plot(history.history['mae'])\n",
    "    ax[1].plot(history.history['val_mae'])\n",
    "    ax[1].set_title('MAE')\n",
    "    ax[1].set_ylabel('MAE')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions (training and evaluating)** ‚ùì\n",
    "\n",
    "- Code the `fit_model()` method that \n",
    "    - <i>(input)</i> given `model`\n",
    "    - <i>(output)</i> returns the fitted model through a tuple `(model, history)` \n",
    "- Then:\n",
    "    - Initialize an RNN model with the `init_model` function\n",
    "    - <font color=blue>Train</font> the model\n",
    "    - <font color=orange>Evaluate</font> it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.2) A Baseline Model to compare our LSTM with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ In Time Series, an \"intuitive\" baseline model is to predict the **last seen value** for the future value(s) you want to forecast, as illustrated down below!\n",
    "\n",
    "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/rnn_time_series_no_horizon.png\" width = 600, height = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Last Seen Value Baseline Model)** ‚ùì \n",
    "\n",
    "Create a new method `init_baseline` that initializes and compiles a baseline model in a similar way to the LSTM.\n",
    "\n",
    "- The baseline should be as a [üìö Keras Lambda Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda)\n",
    "- It should not even need a `fit` because it should have 0 trainable params\n",
    "- Then, compute the MAE for this FOLD and compare it with the MAE you obtained on the test set after training the LSTM \n",
    " \n",
    "<details>\n",
    "    <summary markdown='span'>üí° <i>Hint</i></summary>\n",
    "\n",
    "- Remember that `X_train[:,:,1]` is your temperature time-series (it's the second column in your `fold`) \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "def init_baseline():\n",
    "\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = init_baseline()\n",
    "baseline_score = baseline_model.evaluate(X_test, y_test)\n",
    "print(f\"- The Baseline MAE on the test set is equal to {round(baseline_score[1],2)} Celsius degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"- The LSTM MAE on the test set is equal to {round(res[1],2)} Celsius degrees\")\n",
    "print(f\"üî• Improvement of the LSTM model over the baseline (on this fold for the test set) = : {round((1 - (res[1]/baseline_score[1]))*100,2)} % üî•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.3) Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember **\"The big picture\"** ? \n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'><i>The big picture</i></summary>\n",
    "\n",
    "\n",
    "<b><u>Step 1: Cross-Validation in Time Series [FOLDS] </u></b>\n",
    "\n",
    "* Starting from this single Time Series, we will create <font color=\"#c91ac9\">**FOLDS**</font>...\n",
    "* ... and train/evaluate our LSTM on these different <font color=\"#c91ac9\">**FOLDS**</font> to conclude about the robustness of the neural network\n",
    "* It is very common to create ***hundreds*** of <font color=\"#c91ac9\">**FOLDS**</font> in Time Series forecasting, so as to cover all type of external conditions: e.g.\n",
    "    - crash market periods üìâ\n",
    "    - bull markets üìà\n",
    "    - atone markets üò¥, etc...\n",
    "\n",
    "<b><u>Step 2: Holdout method within each fold [TRAIN-TEST SPLIT]</u></b>\n",
    "\n",
    "* For each <font color=\"#c91ac9\">**FOLD**</font>, we will do a TRAIN-TEST SPLIT to:\n",
    "    * <font color=blue>**fit**</font> the model on the <font color=blue>**train**</font> set \n",
    "    * and <font color=\"#ff8005\">**evaluate**</font> it on the <font color=\"#ff8005\">**test**</font> set\n",
    "    * Always split the train set **chronologically** before the test set!\n",
    "\n",
    "üëá The first two steps can be summarized in the following image that contains 4 FOLDS:\n",
    "\n",
    "<img src=\"https://bit.ly/3yLoa92\" alt=\"Time Series Cross Validation\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "<b><u>Step 3: Sampling SEQUENCES in both the train set and the test set</u></b>\n",
    "\n",
    "In each <font color=blue>**train**</font> set and each <font color=\"#ff8005\">**test**</font> set, we will create <font color=magenta>**random sequences**</font> as illustrated down below üëá:\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> \n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "‚ùóÔ∏è ***Warnings*** ‚ùóÔ∏è\n",
    "\n",
    "* Keep in mind that we did <u><i>step 2</i></u> (<font color=\"blue\">train</font>/<font color=\"orange\">test</font> split) and <u><i>step 3</i></u> (get_X_y) only **<font color=\"#c91ac9\">for one single FOLD</font>**. \n",
    "* ***If we want to ensure the robustness of a model, we need to <font color=\"\">cross-validate the model on <font color=\"#c91ac9\">ALL the folds</font>!***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminders of the global variables in this notebook\n",
    "\n",
    "print(f'N_FEATURES = {N_FEATURES}') \n",
    "print(f'N_TARGETS = {N_TARGETS}') \n",
    "print('')\n",
    "print(f'FOLD_LENGTH = {FOLD_LENGTH}')\n",
    "print(f'FOLD_STRIDE = {FOLD_STRIDE}')\n",
    "print(f'TRAIN_TEST_RATIO = {TRAIN_TEST_RATIO}')\n",
    "print('')\n",
    "print(f'N_TRAIN = {N_TRAIN}')\n",
    "print(f'N_TEST = {N_TEST}')\n",
    "print(f'INPUT_LENGTH = {INPUT_LENGTH}')\n",
    "print(f'OUTPUT_LENGTH = {OUTPUT_LENGTH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember how many folds do we have ?\n",
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "\n",
    "print(f\"WARNING, we have {len(folds)} FOLDS, so you may want to run the cross-validation of the RNN on Colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ùì Cross validate your baseline and your model in a for-loop!‚ùì**\n",
    "\n",
    "Re-using your previously defined methods\n",
    "- `get_folds`\n",
    "- `train_test_split`\n",
    "- `get_X_y`\n",
    "- `init_model`\n",
    "- `init_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def cross_validate_baseline_and_lstm():\n",
    "    '''\n",
    "    This function cross-validates \n",
    "    - the \"last seen value\" baseline model\n",
    "    - the RNN model\n",
    "    '''\n",
    "    \n",
    "    list_of_mae_baseline_model = []\n",
    "    list_of_mae_recurrent_model = []\n",
    "    \n",
    "    # 0 - Creating folds\n",
    "    # =========================================    \n",
    "    folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "    \n",
    "    for fold_id, fold in enumerate(folds):\n",
    "        \n",
    "        # 1 - Train/Test split the current fold\n",
    "        # =========================================\n",
    "        (fold_train, fold_test) = train_test_split(fold, TRAIN_TEST_RATIO, INPUT_LENGTH)                   \n",
    "\n",
    "        X_train, y_train = get_X_y(fold_train, N_TRAIN, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "        X_test, y_test = get_X_y(fold_test, N_TEST, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "        \n",
    "        # 2 - Modelling\n",
    "        # =========================================\n",
    "        \n",
    "        ##### Baseline Model\n",
    "        baseline_model = init_baseline()\n",
    "        mae_baseline = baseline_model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "        list_of_mae_baseline_model.append(mae_baseline)\n",
    "        print(\"-\"*50)\n",
    "        print(f\"MAE baseline fold n¬∞{fold_id} = {round(mae_baseline, 2)}\")\n",
    "\n",
    "        ##### LSTM Model\n",
    "        model = init_model(X_train, y_train)\n",
    "        es = EarlyStopping(monitor = \"val_mae\",\n",
    "                           mode = \"min\",\n",
    "                           patience = 2, \n",
    "                           restore_best_weights = True)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_split = 0.3,\n",
    "                            shuffle = False,\n",
    "                            batch_size = 32,\n",
    "                            epochs = 50,\n",
    "                            callbacks = [es],\n",
    "                            verbose = 0)\n",
    "        res = model.evaluate(X_test, y_test, verbose=0)\n",
    "        mae_lstm = res[1]\n",
    "        list_of_mae_recurrent_model.append(mae_lstm)\n",
    "        print(f\"MAE LSTM fold n¬∞{fold_id} = {round(mae_lstm, 2)}\")\n",
    "        \n",
    "        ##### Comparison LSTM vs Baseline for the current fold\n",
    "        print(f\"üèãüèΩ‚Äç‚ôÇÔ∏è improvement over baseline: {round((1 - (mae_lstm/mae_baseline))*100,2)} % \\n\")\n",
    "\n",
    "    return list_of_mae_baseline_model, list_of_mae_recurrent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# WARNING : it takes 75 minutes to run this cell \n",
    "mae_baselines, mae_lstms = cross_validate_baseline_and_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"average percentage improvement over baseline = {round(np.mean(1 - (np.array(mae_lstms)/np.array(mae_baselines))),2)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This challenge was truly inspired by the `Time Series Forecasting` tutorial from `Google>Tensorflow>Keras`\n",
    "* The technical functions were inspired by Bruno Lajoie's [data-template package about Time Series](https://github.com/lewagon/data-templates/tree/main/project-boilerplates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
